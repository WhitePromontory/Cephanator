{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T15:52:10.166114800Z",
     "start_time": "2026-01-25T15:52:09.074945300Z"
    }
   },
   "source": [
    "from dataset import AarizDataset\n",
    "import torch\n",
    "path = \"Aariz Dataset\"\n",
    "dataset = AarizDataset( path ,\"TRAIN\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)         # should be like \"12.1\" / \"12.4\", not None\n",
    "print(torch.backends.cuda.is_built())\n",
    "print(torch.cuda.is_available())\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0+cu126\n",
      "12.6\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T15:55:34.056389Z",
     "start_time": "2026-01-25T15:55:33.976984600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "\n",
    "folder = \"Aariz Dataset/train/Cephalograms\"\n",
    "\n",
    "max_width = max_height = 0\n",
    "\n",
    "num_folders = 0\n",
    "\n",
    "for f in os.listdir(folder):\n",
    "    num_folders += 1\n",
    "    if f.lower().endswith(\".png\") or f.lower().endswith(\".jpg\") or f.lower().endswith(\".jpeg\") or f.lower().endswith(\".bmp\"):\n",
    "        with Image.open(os.path.join(folder, f)) as img:\n",
    "            w, h = img.size\n",
    "            if max_height == 0:\n",
    "                print(h,w)\n",
    "            max_height = max(max_height, h)\n",
    "            max_width = max(max_width, w)\n",
    "\n",
    "print(\"Max width:\", max_width)\n",
    "print(\"Max height:\", max_height)\n",
    "print(\"Number of files:\", num_folders)"
   ],
   "id": "1e34f5605e45d697",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2225 1968\n",
      "Max width: 2198\n",
      "Max height: 2719\n",
      "Number of files: 700\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T14:42:01.447843300Z",
     "start_time": "2026-01-25T14:42:01.369077400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image, landmarks, cvm = dataset[120]\n",
    "print(image.size())\n",
    "print(landmarks.size())"
   ],
   "id": "60d8385ad0810f4f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2300, 2200])\n",
      "torch.Size([29, 2])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T13:10:28.152716900Z",
     "start_time": "2026-01-25T13:10:24.683001400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "label = \"A Point\"\n",
    "\n",
    "def draw_labeled_point(img, x, y, label, point_color = (0.0,255), label_color=(0,0,0)):\n",
    "    cv2.circle(img, (x, y), 5, point_color, -1)\n",
    "    cv2.putText(img, label, (x+6, y-6),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, label_color, 1)\n",
    "\n",
    "x, y = 1313, 1133\n",
    "\n",
    "# scale factor for display only\n",
    "scale = 0.3\n",
    "\n",
    "# ---- tensor â†’ numpy ----\n",
    "img = image.detach().cpu().numpy()\n",
    "\n",
    "# handle channel-first tensors\n",
    "# (3, H, W) RGB\n",
    "img = img.transpose(1, 2, 0)\n",
    "# (H,W,3)\n",
    "\n",
    "# ---- resize for display ----\n",
    "img_disp = cv2.resize(img, (0, 0), fx=scale, fy=scale)\n",
    "\n",
    "# scaled landmark\n",
    "x_s = int(x * scale)\n",
    "y_s = int(y * scale)\n",
    "\n",
    "# ---- draw landmark ---- # color\n",
    "\n",
    "\n",
    "draw_labeled_point(img_disp, x_s, y_s,label)\n",
    "\n",
    "# ---- show ----\n",
    "cv2.imshow(\"check\", img_disp)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "c2746465cd35e92c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T13:10:28.220010Z",
     "start_time": "2026-01-25T13:10:28.209523800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "H0, W0 = 2300, 2200 # target H, W\n",
    "\n",
    "C, H, W = image.shape\n",
    "\n",
    "pad_bottom = H0 - H\n",
    "pad_right  = W0 - W\n",
    "\n",
    "# pad format: (left, right, top, bottom)\n",
    "pad = (0, pad_right, 0, pad_bottom)\n",
    "\n",
    "image_padded = F.pad(image, pad, value=0)"
   ],
   "id": "e040c2a114556ad5",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T15:40:49.208243200Z",
     "start_time": "2026-01-25T15:40:48.135500800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import AarizDataset\n",
    "path = \"Aariz Dataset\"\n",
    "dataset = AarizDataset( path ,\"TRAIN\")\n",
    "\n",
    "batch_size = 64\n",
    "training_data = AarizDataset( path ,\"TRAIN\")\n",
    "\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size,shuffle=True)"
   ],
   "id": "ba6821000205efa4",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T15:40:52.498038800Z",
     "start_time": "2026-01-25T15:40:50.614467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for (images, landmarks,_) in train_dataloader:\n",
    "    print(f\"Shape of Image Batch: {images.shape}\")\n",
    "    print(f\"Shape of Landmark Batch: {landmarks.shape} {landmarks.dtype}\")\n",
    "    break\n"
   ],
   "id": "2b8ca26ed64f51d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Image Batch: torch.Size([64, 3, 2800, 2200])\n",
      "Shape of Landmark Batch: torch.Size([64, 29, 2]) torch.float32\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "\n",
   "id": "78207fdebd3d719f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
