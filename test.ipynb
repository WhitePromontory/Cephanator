{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T17:29:56.581627100Z",
     "start_time": "2026-01-27T17:29:18.491954300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataset import AarizDataset\n",
    "import torch\n",
    "path = \"Aariz Dataset\"\n",
    "dataset = AarizDataset( path ,\"TRAIN\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "image, landmarks, cvm = dataset[120]\n",
    "print(image.size())\n",
    "print(landmarks.size())\n",
    "import cv2\n",
    "from config import ANATOMICAL_LANDMARKS\n",
    "from helper import draw_points\n",
    "\n",
    "\n",
    "\n",
    "# (H,W,3)\n",
    "\n",
    "\n",
    "# ---- draw landmark ---- # color\n",
    "\n",
    "img = draw_points(image, landmarks,point_radius=2, font_scale=0.5)\n",
    "\n",
    "\n",
    "# ---- show ----\n",
    "cv2.imshow(\"check\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "7f79480acafeede4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2750, 2200])\n",
      "torch.Size([29, 2])\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T17:26:49.927466Z",
     "start_time": "2026-01-27T17:26:41.769094900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "label = \"A Point\"\n",
    "\n",
    "def draw_labeled_point(img, x, y, label, point_color = (0.0,255), label_color=(0,0,0)):\n",
    "    cv2.circle(img, (x, y), 5, point_color, -1)\n",
    "    cv2.putText(img, label, (x+6, y-6),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, label_color, 1)\n",
    "\n",
    "x, y = 1313, 1133\n",
    "\n",
    "# scale factor for display only\n",
    "scale = 0.3\n",
    "\n",
    "# ---- tensor â†’ numpy ----\n",
    "img = image.detach().cpu().numpy()\n",
    "\n",
    "# handle channel-first tensors\n",
    "# (3, H, W) RGB\n",
    "img = img.transpose(1, 2, 0)\n",
    "# (H,W,3)\n",
    "\n",
    "# ---- resize for display ----\n",
    "img_disp = cv2.resize(img, (0, 0), fx=scale, fy=scale)\n",
    "\n",
    "# scaled landmark\n",
    "x_s = int(x * scale)\n",
    "y_s = int(y * scale)\n",
    "\n",
    "# ---- draw landmark ---- # color\n",
    "\n",
    "\n",
    "draw_labeled_point(img_disp, x_s, y_s,label)\n",
    "\n",
    "# ---- show ----\n",
    "cv2.imshow(\"check\", img_disp)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "c0e062618e7c08",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T17:26:49.986567500Z",
     "start_time": "2026-01-27T17:26:49.951898400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import AarizDataset\n",
    "path = \"Aariz Dataset\"\n",
    "dataset = AarizDataset( path ,\"TRAIN\")\n",
    "\n",
    "batch_size = 64\n",
    "training_data = AarizDataset( path ,\"TRAIN\")\n",
    "\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size,shuffle=True)"
   ],
   "id": "ba6821000205efa4",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T17:26:53.918642Z",
     "start_time": "2026-01-27T17:26:50.013981400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for (images, landmarks,_) in train_dataloader:\n",
    "    print(f\"Shape of Image Batch: {images.shape}\")\n",
    "    print(f\"Shape of Landmark Batch: {landmarks.shape} {landmarks.dtype}\")\n",
    "    break\n"
   ],
   "id": "2b8ca26ed64f51d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Image Batch: torch.Size([64, 3, 2750, 2200])\n",
      "Shape of Landmark Batch: torch.Size([64, 29, 2]) torch.float32\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T17:26:54.070535800Z",
     "start_time": "2026-01-27T17:26:53.953818700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "junior_path = \"Aariz Dataset/train/Annotations/Cephalometric Landmarks/Junior Orthodontists\"\n",
    "senior_path = \"Aariz Dataset/train/Annotations/Cephalometric Landmarks/Senior Orthodontists\"\n",
    "\n",
    "with open(junior_path, mode=\"r\") as file:\n",
    "    junior_annotations = json.load(file)\n",
    "\n",
    "with open(senior_path, mode=\"r\") as file:\n",
    "    senior_annotations = json.load(file)\n",
    "\n"
   ],
   "id": "d54dbe3778c5ef05",
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'Aariz Dataset/train/Annotations/Cephalometric Landmarks/Junior Orthodontists'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mPermissionError\u001B[39m                           Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 6\u001B[39m\n\u001B[32m      3\u001B[39m junior_path = \u001B[33m\"\u001B[39m\u001B[33mAariz Dataset/train/Annotations/Cephalometric Landmarks/Junior Orthodontists\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m      4\u001B[39m senior_path = \u001B[33m\"\u001B[39m\u001B[33mAariz Dataset/train/Annotations/Cephalometric Landmarks/Senior Orthodontists\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mjunior_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mr\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m file:\n\u001B[32m      7\u001B[39m     junior_annotations = json.load(file)\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(senior_path, mode=\u001B[33m\"\u001B[39m\u001B[33mr\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m file:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Cephanator\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:344\u001B[39m, in \u001B[36m_modified_open\u001B[39m\u001B[34m(file, *args, **kwargs)\u001B[39m\n\u001B[32m    337\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[32m0\u001B[39m, \u001B[32m1\u001B[39m, \u001B[32m2\u001B[39m}:\n\u001B[32m    338\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    339\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mIPython won\u001B[39m\u001B[33m'\u001B[39m\u001B[33mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m by default \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    340\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    341\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33myou can use builtins\u001B[39m\u001B[33m'\u001B[39m\u001B[33m open.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    342\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m344\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mPermissionError\u001B[39m: [Errno 13] Permission denied: 'Aariz Dataset/train/Annotations/Cephalometric Landmarks/Junior Orthodontists'"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "\n",
   "id": "78207fdebd3d719f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
