{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T21:41:44.578267600Z",
     "start_time": "2026-02-01T21:41:39.572863700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from helper import  draw_batch\n",
    "import torch\n",
    "from dataset import AarizDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from CephNet import CephNet\n",
    "\n",
    "\n",
    "print(f\"Device: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"Compute Capability: {torch.cuda.get_device_capability(0)}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"PyTorch CUDA: {torch.version.cuda}\")\n",
    "\n",
    "path = \"Aariz Dataset\"#\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model  = CephNet()\n",
    "\n",
    "model.to(device)\n",
    "batch_size = 5\n",
    "\n",
    "training_data = AarizDataset( path ,\"TRAIN\")\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size,shuffle=True)\n",
    "\n",
    "for (images, landmarks) in train_dataloader:\n",
    "    images = images.to(device)\n",
    "    print(f\"Shape of Image Batch: {images.shape}\")\n",
    "    print(f\"Shape of Landmark Batch: {landmarks.shape} {landmarks.dtype}\")\n",
    "    # draw_batch(images, landmarks)\n",
    "    output =model(images)\n",
    "    print(f\"Shape of Output batch: {output.shape}\")\n",
    "    break\n",
    "\n"
   ],
   "id": "2b8ca26ed64f51d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: NVIDIA GeForce RTX 5080 Laptop GPU\n",
      "Compute Capability: (12, 0)\n",
      "PyTorch Version: 2.10.0+cu128\n",
      "PyTorch CUDA: 12.8\n",
      "Shape of Image Batch: torch.Size([5, 3, 512, 512])\n",
      "Shape of Landmark Batch: torch.Size([5, 29, 2]) torch.float32\n",
      "Shape of Output batch: torch.Size([5, 29, 2])\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6d41b785cfc662e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T23:19:57.523627600Z",
     "start_time": "2026-02-01T21:41:44.581278300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import AarizDataset\n",
    "from CephNet import CephNet,train,validate,test\n",
    "from torch import optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model = CephNet()\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(\"best_model_epoch_95.pth\"))\n",
    "\n",
    "\n",
    "path = \"Aariz Dataset\"\n",
    "\n",
    "batch_size = 5\n",
    "\n",
    "training_data = AarizDataset( path ,\"TRAIN\")\n",
    "val_data = AarizDataset( path ,\"VALID\")\n",
    "test_data = AarizDataset( path ,\"TEST\")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size,shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=batch_size,shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size,shuffle=True)\n",
    "\n",
    "\n",
    "num_epochs = 300\n",
    "loss_fn = nn.SmoothL1Loss(beta=1.0)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5, weight_decay=1e-2)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=7, factor=0.1)\n",
    "\n",
    "checkpoint = torch.load(\"last_checkpoint.pth\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "best_euclid = checkpoint['best_euclid']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# float(\"inf\")\n",
    "\n",
    "file_name = \"best_model_epoch_95.pth\"\n",
    "\n",
    "for epoch in range (152,num_epochs+1):\n",
    "    print(f\"\\n--- Epoch {epoch}/{num_epochs} ---\")\n",
    "\n",
    "    # 1. TRAIN\n",
    "    # Returns (epoch_loss, avg_euclid)\n",
    "    train_loss, train_euclid = train(model, train_dataloader, loss_fn, optimizer, device, epoch)\n",
    "\n",
    "    # 2. VALIDATE\n",
    "    # Returns (epoch_loss, avg_euclid)\n",
    "    val_loss, val_euclid = validate(model, val_dataloader, loss_fn, device, epoch)\n",
    "\n",
    "    # 3. UPDATE SCHEDULER\n",
    "    # ReduceLROnPlateau watches the Validation Loss\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # 4. Check for overfitting\n",
    "    if val_euclid < best_euclid:\n",
    "        best_euclid = val_euclid\n",
    "        file_name = f\"best_model_epoch_{epoch}.pth\"\n",
    "        torch.save(model.state_dict(), file_name)\n",
    "        print(f\"⭐ New Best Model Saved! (Best MRE: {best_euclid:.6f})\")\n",
    "\n",
    "    checkpoint = {\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'scheduler_state_dict': scheduler.state_dict(), # This is the missing piece!\n",
    "    'best_euclid': best_euclid\n",
    "}\n",
    "    torch.save(checkpoint, \"last_checkpoint.pth\")\n",
    "\n",
    "# ==========================================\n",
    "# FINAL TEST PHASE (After Training Finishes)\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"TRAINING COMPLETE. RUNNING FINAL TEST...\")\n",
    "\n",
    "# Load the weights from the BEST performing epoch\n",
    "model.load_state_dict(torch.load(file_name))\n",
    "\n",
    "# Run the test function on the unseen Test Set\n",
    "final_loss, final_mre = test(model, test_dataloader, loss_fn, device, \"FINAL\")\n",
    "\n",
    "#79\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "e9769c4e318bfe84",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 152/300 ---\n",
      "Epoch: 152 | Average Training Loss: 0.000002\n",
      "Epoch: 152 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 152 | Average Val Loss: 0.000070\n",
      "Epoch: 152 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 153/300 ---\n",
      "Epoch: 153 | Average Training Loss: 0.000002\n",
      "Epoch: 153 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 153 | Average Val Loss: 0.000071\n",
      "Epoch: 153 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 154/300 ---\n",
      "Epoch: 154 | Average Training Loss: 0.000002\n",
      "Epoch: 154 | Average Euclidean Distance: 0.0027\n",
      "Epoch: 154 | Average Val Loss: 0.000068\n",
      "Epoch: 154 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 155/300 ---\n",
      "Epoch: 155 | Average Training Loss: 0.000002\n",
      "Epoch: 155 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 155 | Average Val Loss: 0.000072\n",
      "Epoch: 155 | Average Euclidean Distance: 0.0140\n",
      "\n",
      "--- Epoch 156/300 ---\n",
      "Epoch: 156 | Average Training Loss: 0.000002\n",
      "Epoch: 156 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 156 | Average Val Loss: 0.000068\n",
      "Epoch: 156 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 157/300 ---\n",
      "Epoch: 157 | Average Training Loss: 0.000002\n",
      "Epoch: 157 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 157 | Average Val Loss: 0.000068\n",
      "Epoch: 157 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 158/300 ---\n",
      "Epoch: 158 | Average Training Loss: 0.000002\n",
      "Epoch: 158 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 158 | Average Val Loss: 0.000068\n",
      "Epoch: 158 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 159/300 ---\n",
      "Epoch: 159 | Average Training Loss: 0.000002\n",
      "Epoch: 159 | Average Euclidean Distance: 0.0027\n",
      "Epoch: 159 | Average Val Loss: 0.000068\n",
      "Epoch: 159 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 160/300 ---\n",
      "Epoch: 160 | Average Training Loss: 0.000002\n",
      "Epoch: 160 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 160 | Average Val Loss: 0.000067\n",
      "Epoch: 160 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 161/300 ---\n",
      "Epoch: 161 | Average Training Loss: 0.000002\n",
      "Epoch: 161 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 161 | Average Val Loss: 0.000069\n",
      "Epoch: 161 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 162/300 ---\n",
      "Epoch: 162 | Average Training Loss: 0.000002\n",
      "Epoch: 162 | Average Euclidean Distance: 0.0027\n",
      "Epoch: 162 | Average Val Loss: 0.000073\n",
      "Epoch: 162 | Average Euclidean Distance: 0.0140\n",
      "\n",
      "--- Epoch 163/300 ---\n",
      "Epoch: 163 | Average Training Loss: 0.000002\n",
      "Epoch: 163 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 163 | Average Val Loss: 0.000067\n",
      "Epoch: 163 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 164/300 ---\n",
      "Epoch: 164 | Average Training Loss: 0.000002\n",
      "Epoch: 164 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 164 | Average Val Loss: 0.000073\n",
      "Epoch: 164 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 165/300 ---\n",
      "Epoch: 165 | Average Training Loss: 0.000002\n",
      "Epoch: 165 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 165 | Average Val Loss: 0.000069\n",
      "Epoch: 165 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 166/300 ---\n",
      "Epoch: 166 | Average Training Loss: 0.000002\n",
      "Epoch: 166 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 166 | Average Val Loss: 0.000068\n",
      "Epoch: 166 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 167/300 ---\n",
      "Epoch: 167 | Average Training Loss: 0.000002\n",
      "Epoch: 167 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 167 | Average Val Loss: 0.000076\n",
      "Epoch: 167 | Average Euclidean Distance: 0.0141\n",
      "\n",
      "--- Epoch 168/300 ---\n",
      "Epoch: 168 | Average Training Loss: 0.000002\n",
      "Epoch: 168 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 168 | Average Val Loss: 0.000071\n",
      "Epoch: 168 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 169/300 ---\n",
      "Epoch: 169 | Average Training Loss: 0.000002\n",
      "Epoch: 169 | Average Euclidean Distance: 0.0027\n",
      "Epoch: 169 | Average Val Loss: 0.000068\n",
      "Epoch: 169 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 170/300 ---\n",
      "Epoch: 170 | Average Training Loss: 0.000002\n",
      "Epoch: 170 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 170 | Average Val Loss: 0.000070\n",
      "Epoch: 170 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 171/300 ---\n",
      "Epoch: 171 | Average Training Loss: 0.000002\n",
      "Epoch: 171 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 171 | Average Val Loss: 0.000070\n",
      "Epoch: 171 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 172/300 ---\n",
      "Epoch: 172 | Average Training Loss: 0.000002\n",
      "Epoch: 172 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 172 | Average Val Loss: 0.000070\n",
      "Epoch: 172 | Average Euclidean Distance: 0.0140\n",
      "\n",
      "--- Epoch 173/300 ---\n",
      "Epoch: 173 | Average Training Loss: 0.000002\n",
      "Epoch: 173 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 173 | Average Val Loss: 0.000067\n",
      "Epoch: 173 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 174/300 ---\n",
      "Epoch: 174 | Average Training Loss: 0.000002\n",
      "Epoch: 174 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 174 | Average Val Loss: 0.000070\n",
      "Epoch: 174 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 175/300 ---\n",
      "Epoch: 175 | Average Training Loss: 0.000002\n",
      "Epoch: 175 | Average Euclidean Distance: 0.0027\n",
      "Epoch: 175 | Average Val Loss: 0.000069\n",
      "Epoch: 175 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 176/300 ---\n",
      "Epoch: 176 | Average Training Loss: 0.000002\n",
      "Epoch: 176 | Average Euclidean Distance: 0.0027\n",
      "Epoch: 176 | Average Val Loss: 0.000068\n",
      "Epoch: 176 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 177/300 ---\n",
      "Epoch: 177 | Average Training Loss: 0.000002\n",
      "Epoch: 177 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 177 | Average Val Loss: 0.000071\n",
      "Epoch: 177 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 178/300 ---\n",
      "Epoch: 178 | Average Training Loss: 0.000002\n",
      "Epoch: 178 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 178 | Average Val Loss: 0.000079\n",
      "Epoch: 178 | Average Euclidean Distance: 0.0141\n",
      "\n",
      "--- Epoch 179/300 ---\n",
      "Epoch: 179 | Average Training Loss: 0.000002\n",
      "Epoch: 179 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 179 | Average Val Loss: 0.000071\n",
      "Epoch: 179 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 180/300 ---\n",
      "Epoch: 180 | Average Training Loss: 0.000002\n",
      "Epoch: 180 | Average Euclidean Distance: 0.0027\n",
      "Epoch: 180 | Average Val Loss: 0.000067\n",
      "Epoch: 180 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 181/300 ---\n",
      "Epoch: 181 | Average Training Loss: 0.000002\n",
      "Epoch: 181 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 181 | Average Val Loss: 0.000071\n",
      "Epoch: 181 | Average Euclidean Distance: 0.0140\n",
      "\n",
      "--- Epoch 182/300 ---\n",
      "Epoch: 182 | Average Training Loss: 0.000002\n",
      "Epoch: 182 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 182 | Average Val Loss: 0.000069\n",
      "Epoch: 182 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 183/300 ---\n",
      "Epoch: 183 | Average Training Loss: 0.000002\n",
      "Epoch: 183 | Average Euclidean Distance: 0.0027\n",
      "Epoch: 183 | Average Val Loss: 0.000069\n",
      "Epoch: 183 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 184/300 ---\n",
      "Epoch: 184 | Average Training Loss: 0.000002\n",
      "Epoch: 184 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 184 | Average Val Loss: 0.000070\n",
      "Epoch: 184 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 185/300 ---\n",
      "Epoch: 185 | Average Training Loss: 0.000002\n",
      "Epoch: 185 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 185 | Average Val Loss: 0.000068\n",
      "Epoch: 185 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 186/300 ---\n",
      "Epoch: 186 | Average Training Loss: 0.000002\n",
      "Epoch: 186 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 186 | Average Val Loss: 0.000067\n",
      "Epoch: 186 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 187/300 ---\n",
      "Epoch: 187 | Average Training Loss: 0.000002\n",
      "Epoch: 187 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 187 | Average Val Loss: 0.000070\n",
      "Epoch: 187 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 188/300 ---\n",
      "Epoch: 188 | Average Training Loss: 0.000002\n",
      "Epoch: 188 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 188 | Average Val Loss: 0.000069\n",
      "Epoch: 188 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 189/300 ---\n",
      "Epoch: 189 | Average Training Loss: 0.000002\n",
      "Epoch: 189 | Average Euclidean Distance: 0.0027\n",
      "Epoch: 189 | Average Val Loss: 0.000068\n",
      "Epoch: 189 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 190/300 ---\n",
      "Epoch: 190 | Average Training Loss: 0.000002\n",
      "Epoch: 190 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 190 | Average Val Loss: 0.000067\n",
      "Epoch: 190 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 191/300 ---\n",
      "Epoch: 191 | Average Training Loss: 0.000002\n",
      "Epoch: 191 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 191 | Average Val Loss: 0.000069\n",
      "Epoch: 191 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 192/300 ---\n",
      "Epoch: 192 | Average Training Loss: 0.000002\n",
      "Epoch: 192 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 192 | Average Val Loss: 0.000072\n",
      "Epoch: 192 | Average Euclidean Distance: 0.0140\n",
      "\n",
      "--- Epoch 193/300 ---\n",
      "Epoch: 193 | Average Training Loss: 0.000002\n",
      "Epoch: 193 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 193 | Average Val Loss: 0.000070\n",
      "Epoch: 193 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 194/300 ---\n",
      "Epoch: 194 | Average Training Loss: 0.000002\n",
      "Epoch: 194 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 194 | Average Val Loss: 0.000071\n",
      "Epoch: 194 | Average Euclidean Distance: 0.0140\n",
      "\n",
      "--- Epoch 195/300 ---\n",
      "Epoch: 195 | Average Training Loss: 0.000002\n",
      "Epoch: 195 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 195 | Average Val Loss: 0.000067\n",
      "Epoch: 195 | Average Euclidean Distance: 0.0138\n",
      "⭐ New Best Model Saved! (Best MRE: 0.013767)\n",
      "\n",
      "--- Epoch 196/300 ---\n",
      "Epoch: 196 | Average Training Loss: 0.000002\n",
      "Epoch: 196 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 196 | Average Val Loss: 0.000070\n",
      "Epoch: 196 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 197/300 ---\n",
      "Epoch: 197 | Average Training Loss: 0.000002\n",
      "Epoch: 197 | Average Euclidean Distance: 0.0027\n",
      "Epoch: 197 | Average Val Loss: 0.000067\n",
      "Epoch: 197 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 198/300 ---\n",
      "Epoch: 198 | Average Training Loss: 0.000002\n",
      "Epoch: 198 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 198 | Average Val Loss: 0.000069\n",
      "Epoch: 198 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 199/300 ---\n",
      "Epoch: 199 | Average Training Loss: 0.000002\n",
      "Epoch: 199 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 199 | Average Val Loss: 0.000069\n",
      "Epoch: 199 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 200/300 ---\n",
      "Epoch: 200 | Average Training Loss: 0.000002\n",
      "Epoch: 200 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 200 | Average Val Loss: 0.000070\n",
      "Epoch: 200 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 201/300 ---\n",
      "Epoch: 201 | Average Training Loss: 0.000002\n",
      "Epoch: 201 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 201 | Average Val Loss: 0.000068\n",
      "Epoch: 201 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 202/300 ---\n",
      "Epoch: 202 | Average Training Loss: 0.000002\n",
      "Epoch: 202 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 202 | Average Val Loss: 0.000069\n",
      "Epoch: 202 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 203/300 ---\n",
      "Epoch: 203 | Average Training Loss: 0.000002\n",
      "Epoch: 203 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 203 | Average Val Loss: 0.000070\n",
      "Epoch: 203 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 204/300 ---\n",
      "Epoch: 204 | Average Training Loss: 0.000002\n",
      "Epoch: 204 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 204 | Average Val Loss: 0.000072\n",
      "Epoch: 204 | Average Euclidean Distance: 0.0140\n",
      "\n",
      "--- Epoch 205/300 ---\n",
      "Epoch: 205 | Average Training Loss: 0.000002\n",
      "Epoch: 205 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 205 | Average Val Loss: 0.000070\n",
      "Epoch: 205 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 206/300 ---\n",
      "Epoch: 206 | Average Training Loss: 0.000002\n",
      "Epoch: 206 | Average Euclidean Distance: 0.0027\n",
      "Epoch: 206 | Average Val Loss: 0.000071\n",
      "Epoch: 206 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 207/300 ---\n",
      "Epoch: 207 | Average Training Loss: 0.000002\n",
      "Epoch: 207 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 207 | Average Val Loss: 0.000069\n",
      "Epoch: 207 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 208/300 ---\n",
      "Epoch: 208 | Average Training Loss: 0.000002\n",
      "Epoch: 208 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 208 | Average Val Loss: 0.000070\n",
      "Epoch: 208 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 209/300 ---\n",
      "Epoch: 209 | Average Training Loss: 0.000002\n",
      "Epoch: 209 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 209 | Average Val Loss: 0.000067\n",
      "Epoch: 209 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 210/300 ---\n",
      "Epoch: 210 | Average Training Loss: 0.000002\n",
      "Epoch: 210 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 210 | Average Val Loss: 0.000069\n",
      "Epoch: 210 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 211/300 ---\n",
      "Epoch: 211 | Average Training Loss: 0.000002\n",
      "Epoch: 211 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 211 | Average Val Loss: 0.000069\n",
      "Epoch: 211 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 212/300 ---\n",
      "Epoch: 212 | Average Training Loss: 0.000002\n",
      "Epoch: 212 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 212 | Average Val Loss: 0.000070\n",
      "Epoch: 212 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 213/300 ---\n",
      "Epoch: 213 | Average Training Loss: 0.000002\n",
      "Epoch: 213 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 213 | Average Val Loss: 0.000072\n",
      "Epoch: 213 | Average Euclidean Distance: 0.0140\n",
      "\n",
      "--- Epoch 214/300 ---\n",
      "Epoch: 214 | Average Training Loss: 0.000002\n",
      "Epoch: 214 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 214 | Average Val Loss: 0.000070\n",
      "Epoch: 214 | Average Euclidean Distance: 0.0140\n",
      "\n",
      "--- Epoch 215/300 ---\n",
      "Epoch: 215 | Average Training Loss: 0.000002\n",
      "Epoch: 215 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 215 | Average Val Loss: 0.000068\n",
      "Epoch: 215 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 216/300 ---\n",
      "Epoch: 216 | Average Training Loss: 0.000002\n",
      "Epoch: 216 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 216 | Average Val Loss: 0.000068\n",
      "Epoch: 216 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 217/300 ---\n",
      "Epoch: 217 | Average Training Loss: 0.000002\n",
      "Epoch: 217 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 217 | Average Val Loss: 0.000067\n",
      "Epoch: 217 | Average Euclidean Distance: 0.0138\n",
      "⭐ New Best Model Saved! (Best MRE: 0.013752)\n",
      "\n",
      "--- Epoch 218/300 ---\n",
      "Epoch: 218 | Average Training Loss: 0.000002\n",
      "Epoch: 218 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 218 | Average Val Loss: 0.000072\n",
      "Epoch: 218 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 219/300 ---\n",
      "Epoch: 219 | Average Training Loss: 0.000002\n",
      "Epoch: 219 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 219 | Average Val Loss: 0.000070\n",
      "Epoch: 219 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 220/300 ---\n",
      "Epoch: 220 | Average Training Loss: 0.000002\n",
      "Epoch: 220 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 220 | Average Val Loss: 0.000067\n",
      "Epoch: 220 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 221/300 ---\n",
      "Epoch: 221 | Average Training Loss: 0.000002\n",
      "Epoch: 221 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 221 | Average Val Loss: 0.000072\n",
      "Epoch: 221 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 222/300 ---\n",
      "Epoch: 222 | Average Training Loss: 0.000002\n",
      "Epoch: 222 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 222 | Average Val Loss: 0.000071\n",
      "Epoch: 222 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 223/300 ---\n",
      "Epoch: 223 | Average Training Loss: 0.000002\n",
      "Epoch: 223 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 223 | Average Val Loss: 0.000070\n",
      "Epoch: 223 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 224/300 ---\n",
      "Epoch: 224 | Average Training Loss: 0.000002\n",
      "Epoch: 224 | Average Euclidean Distance: 0.0025\n",
      "Epoch: 224 | Average Val Loss: 0.000068\n",
      "Epoch: 224 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 225/300 ---\n",
      "Epoch: 225 | Average Training Loss: 0.000002\n",
      "Epoch: 225 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 225 | Average Val Loss: 0.000067\n",
      "Epoch: 225 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 226/300 ---\n",
      "Epoch: 226 | Average Training Loss: 0.000002\n",
      "Epoch: 226 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 226 | Average Val Loss: 0.000069\n",
      "Epoch: 226 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 227/300 ---\n",
      "Epoch: 227 | Average Training Loss: 0.000002\n",
      "Epoch: 227 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 227 | Average Val Loss: 0.000068\n",
      "Epoch: 227 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 228/300 ---\n",
      "Epoch: 228 | Average Training Loss: 0.000002\n",
      "Epoch: 228 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 228 | Average Val Loss: 0.000074\n",
      "Epoch: 228 | Average Euclidean Distance: 0.0140\n",
      "\n",
      "--- Epoch 229/300 ---\n",
      "Epoch: 229 | Average Training Loss: 0.000002\n",
      "Epoch: 229 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 229 | Average Val Loss: 0.000068\n",
      "Epoch: 229 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 230/300 ---\n",
      "Epoch: 230 | Average Training Loss: 0.000002\n",
      "Epoch: 230 | Average Euclidean Distance: 0.0027\n",
      "Epoch: 230 | Average Val Loss: 0.000071\n",
      "Epoch: 230 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 231/300 ---\n",
      "Epoch: 231 | Average Training Loss: 0.000002\n",
      "Epoch: 231 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 231 | Average Val Loss: 0.000068\n",
      "Epoch: 231 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 232/300 ---\n",
      "Epoch: 232 | Average Training Loss: 0.000002\n",
      "Epoch: 232 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 232 | Average Val Loss: 0.000069\n",
      "Epoch: 232 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 233/300 ---\n",
      "Epoch: 233 | Average Training Loss: 0.000002\n",
      "Epoch: 233 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 233 | Average Val Loss: 0.000069\n",
      "Epoch: 233 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 234/300 ---\n",
      "Epoch: 234 | Average Training Loss: 0.000002\n",
      "Epoch: 234 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 234 | Average Val Loss: 0.000069\n",
      "Epoch: 234 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 235/300 ---\n",
      "Epoch: 235 | Average Training Loss: 0.000002\n",
      "Epoch: 235 | Average Euclidean Distance: 0.0025\n",
      "Epoch: 235 | Average Val Loss: 0.000071\n",
      "Epoch: 235 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 236/300 ---\n",
      "Epoch: 236 | Average Training Loss: 0.000002\n",
      "Epoch: 236 | Average Euclidean Distance: 0.0027\n",
      "Epoch: 236 | Average Val Loss: 0.000068\n",
      "Epoch: 236 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 237/300 ---\n",
      "Epoch: 237 | Average Training Loss: 0.000002\n",
      "Epoch: 237 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 237 | Average Val Loss: 0.000078\n",
      "Epoch: 237 | Average Euclidean Distance: 0.0141\n",
      "\n",
      "--- Epoch 238/300 ---\n",
      "Epoch: 238 | Average Training Loss: 0.000002\n",
      "Epoch: 238 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 238 | Average Val Loss: 0.000071\n",
      "Epoch: 238 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 239/300 ---\n",
      "Epoch: 239 | Average Training Loss: 0.000002\n",
      "Epoch: 239 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 239 | Average Val Loss: 0.000069\n",
      "Epoch: 239 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 240/300 ---\n",
      "Epoch: 240 | Average Training Loss: 0.000002\n",
      "Epoch: 240 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 240 | Average Val Loss: 0.000072\n",
      "Epoch: 240 | Average Euclidean Distance: 0.0140\n",
      "\n",
      "--- Epoch 241/300 ---\n",
      "Epoch: 241 | Average Training Loss: 0.000002\n",
      "Epoch: 241 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 241 | Average Val Loss: 0.000076\n",
      "Epoch: 241 | Average Euclidean Distance: 0.0141\n",
      "\n",
      "--- Epoch 242/300 ---\n",
      "Epoch: 242 | Average Training Loss: 0.000002\n",
      "Epoch: 242 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 242 | Average Val Loss: 0.000070\n",
      "Epoch: 242 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 243/300 ---\n",
      "Epoch: 243 | Average Training Loss: 0.000002\n",
      "Epoch: 243 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 243 | Average Val Loss: 0.000070\n",
      "Epoch: 243 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 244/300 ---\n",
      "Epoch: 244 | Average Training Loss: 0.000002\n",
      "Epoch: 244 | Average Euclidean Distance: 0.0027\n",
      "Epoch: 244 | Average Val Loss: 0.000076\n",
      "Epoch: 244 | Average Euclidean Distance: 0.0141\n",
      "\n",
      "--- Epoch 245/300 ---\n",
      "Epoch: 245 | Average Training Loss: 0.000002\n",
      "Epoch: 245 | Average Euclidean Distance: 0.0027\n",
      "Epoch: 245 | Average Val Loss: 0.000075\n",
      "Epoch: 245 | Average Euclidean Distance: 0.0141\n",
      "\n",
      "--- Epoch 246/300 ---\n",
      "Epoch: 246 | Average Training Loss: 0.000002\n",
      "Epoch: 246 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 246 | Average Val Loss: 0.000068\n",
      "Epoch: 246 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 247/300 ---\n",
      "Epoch: 247 | Average Training Loss: 0.000002\n",
      "Epoch: 247 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 247 | Average Val Loss: 0.000070\n",
      "Epoch: 247 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 248/300 ---\n",
      "Epoch: 248 | Average Training Loss: 0.000002\n",
      "Epoch: 248 | Average Euclidean Distance: 0.0027\n",
      "Epoch: 248 | Average Val Loss: 0.000068\n",
      "Epoch: 248 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 249/300 ---\n",
      "Epoch: 249 | Average Training Loss: 0.000002\n",
      "Epoch: 249 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 249 | Average Val Loss: 0.000069\n",
      "Epoch: 249 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 250/300 ---\n",
      "Epoch: 250 | Average Training Loss: 0.000002\n",
      "Epoch: 250 | Average Euclidean Distance: 0.0027\n",
      "Epoch: 250 | Average Val Loss: 0.000073\n",
      "Epoch: 250 | Average Euclidean Distance: 0.0140\n",
      "\n",
      "--- Epoch 251/300 ---\n",
      "Epoch: 251 | Average Training Loss: 0.000002\n",
      "Epoch: 251 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 251 | Average Val Loss: 0.000069\n",
      "Epoch: 251 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 252/300 ---\n",
      "Epoch: 252 | Average Training Loss: 0.000002\n",
      "Epoch: 252 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 252 | Average Val Loss: 0.000077\n",
      "Epoch: 252 | Average Euclidean Distance: 0.0141\n",
      "\n",
      "--- Epoch 253/300 ---\n",
      "Epoch: 253 | Average Training Loss: 0.000002\n",
      "Epoch: 253 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 253 | Average Val Loss: 0.000068\n",
      "Epoch: 253 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 254/300 ---\n",
      "Epoch: 254 | Average Training Loss: 0.000002\n",
      "Epoch: 254 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 254 | Average Val Loss: 0.000073\n",
      "Epoch: 254 | Average Euclidean Distance: 0.0140\n",
      "\n",
      "--- Epoch 255/300 ---\n",
      "Epoch: 255 | Average Training Loss: 0.000002\n",
      "Epoch: 255 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 255 | Average Val Loss: 0.000071\n",
      "Epoch: 255 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 256/300 ---\n",
      "Epoch: 256 | Average Training Loss: 0.000002\n",
      "Epoch: 256 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 256 | Average Val Loss: 0.000075\n",
      "Epoch: 256 | Average Euclidean Distance: 0.0140\n",
      "\n",
      "--- Epoch 257/300 ---\n",
      "Epoch: 257 | Average Training Loss: 0.000002\n",
      "Epoch: 257 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 257 | Average Val Loss: 0.000069\n",
      "Epoch: 257 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 258/300 ---\n",
      "Epoch: 258 | Average Training Loss: 0.000002\n",
      "Epoch: 258 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 258 | Average Val Loss: 0.000069\n",
      "Epoch: 258 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 259/300 ---\n",
      "Epoch: 259 | Average Training Loss: 0.000002\n",
      "Epoch: 259 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 259 | Average Val Loss: 0.000068\n",
      "Epoch: 259 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 260/300 ---\n",
      "Epoch: 260 | Average Training Loss: 0.000002\n",
      "Epoch: 260 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 260 | Average Val Loss: 0.000070\n",
      "Epoch: 260 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 261/300 ---\n",
      "Epoch: 261 | Average Training Loss: 0.000002\n",
      "Epoch: 261 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 261 | Average Val Loss: 0.000069\n",
      "Epoch: 261 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 262/300 ---\n",
      "Epoch: 262 | Average Training Loss: 0.000002\n",
      "Epoch: 262 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 262 | Average Val Loss: 0.000067\n",
      "Epoch: 262 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 263/300 ---\n",
      "Epoch: 263 | Average Training Loss: 0.000002\n",
      "Epoch: 263 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 263 | Average Val Loss: 0.000071\n",
      "Epoch: 263 | Average Euclidean Distance: 0.0140\n",
      "\n",
      "--- Epoch 264/300 ---\n",
      "Epoch: 264 | Average Training Loss: 0.000002\n",
      "Epoch: 264 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 264 | Average Val Loss: 0.000073\n",
      "Epoch: 264 | Average Euclidean Distance: 0.0140\n",
      "\n",
      "--- Epoch 265/300 ---\n",
      "Epoch: 265 | Average Training Loss: 0.000002\n",
      "Epoch: 265 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 265 | Average Val Loss: 0.000073\n",
      "Epoch: 265 | Average Euclidean Distance: 0.0140\n",
      "\n",
      "--- Epoch 266/300 ---\n",
      "Epoch: 266 | Average Training Loss: 0.000002\n",
      "Epoch: 266 | Average Euclidean Distance: 0.0027\n",
      "Epoch: 266 | Average Val Loss: 0.000068\n",
      "Epoch: 266 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 267/300 ---\n",
      "Epoch: 267 | Average Training Loss: 0.000002\n",
      "Epoch: 267 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 267 | Average Val Loss: 0.000073\n",
      "Epoch: 267 | Average Euclidean Distance: 0.0140\n",
      "\n",
      "--- Epoch 268/300 ---\n",
      "Epoch: 268 | Average Training Loss: 0.000002\n",
      "Epoch: 268 | Average Euclidean Distance: 0.0027\n",
      "Epoch: 268 | Average Val Loss: 0.000070\n",
      "Epoch: 268 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 269/300 ---\n",
      "Epoch: 269 | Average Training Loss: 0.000002\n",
      "Epoch: 269 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 269 | Average Val Loss: 0.000067\n",
      "Epoch: 269 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 270/300 ---\n",
      "Epoch: 270 | Average Training Loss: 0.000002\n",
      "Epoch: 270 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 270 | Average Val Loss: 0.000075\n",
      "Epoch: 270 | Average Euclidean Distance: 0.0140\n",
      "\n",
      "--- Epoch 271/300 ---\n",
      "Epoch: 271 | Average Training Loss: 0.000002\n",
      "Epoch: 271 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 271 | Average Val Loss: 0.000069\n",
      "Epoch: 271 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 272/300 ---\n",
      "Epoch: 272 | Average Training Loss: 0.000002\n",
      "Epoch: 272 | Average Euclidean Distance: 0.0027\n",
      "Epoch: 272 | Average Val Loss: 0.000074\n",
      "Epoch: 272 | Average Euclidean Distance: 0.0140\n",
      "\n",
      "--- Epoch 273/300 ---\n",
      "Epoch: 273 | Average Training Loss: 0.000002\n",
      "Epoch: 273 | Average Euclidean Distance: 0.0027\n",
      "Epoch: 273 | Average Val Loss: 0.000074\n",
      "Epoch: 273 | Average Euclidean Distance: 0.0140\n",
      "\n",
      "--- Epoch 274/300 ---\n",
      "Epoch: 274 | Average Training Loss: 0.000002\n",
      "Epoch: 274 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 274 | Average Val Loss: 0.000068\n",
      "Epoch: 274 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 275/300 ---\n",
      "Epoch: 275 | Average Training Loss: 0.000002\n",
      "Epoch: 275 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 275 | Average Val Loss: 0.000068\n",
      "Epoch: 275 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 276/300 ---\n",
      "Epoch: 276 | Average Training Loss: 0.000002\n",
      "Epoch: 276 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 276 | Average Val Loss: 0.000068\n",
      "Epoch: 276 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 277/300 ---\n",
      "Epoch: 277 | Average Training Loss: 0.000002\n",
      "Epoch: 277 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 277 | Average Val Loss: 0.000068\n",
      "Epoch: 277 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 278/300 ---\n",
      "Epoch: 278 | Average Training Loss: 0.000002\n",
      "Epoch: 278 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 278 | Average Val Loss: 0.000073\n",
      "Epoch: 278 | Average Euclidean Distance: 0.0140\n",
      "\n",
      "--- Epoch 279/300 ---\n",
      "Epoch: 279 | Average Training Loss: 0.000002\n",
      "Epoch: 279 | Average Euclidean Distance: 0.0027\n",
      "Epoch: 279 | Average Val Loss: 0.000069\n",
      "Epoch: 279 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 280/300 ---\n",
      "Epoch: 280 | Average Training Loss: 0.000002\n",
      "Epoch: 280 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 280 | Average Val Loss: 0.000068\n",
      "Epoch: 280 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 281/300 ---\n",
      "Epoch: 281 | Average Training Loss: 0.000002\n",
      "Epoch: 281 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 281 | Average Val Loss: 0.000073\n",
      "Epoch: 281 | Average Euclidean Distance: 0.0140\n",
      "\n",
      "--- Epoch 282/300 ---\n",
      "Epoch: 282 | Average Training Loss: 0.000002\n",
      "Epoch: 282 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 282 | Average Val Loss: 0.000072\n",
      "Epoch: 282 | Average Euclidean Distance: 0.0140\n",
      "\n",
      "--- Epoch 283/300 ---\n",
      "Epoch: 283 | Average Training Loss: 0.000002\n",
      "Epoch: 283 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 283 | Average Val Loss: 0.000067\n",
      "Epoch: 283 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 284/300 ---\n",
      "Epoch: 284 | Average Training Loss: 0.000002\n",
      "Epoch: 284 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 284 | Average Val Loss: 0.000068\n",
      "Epoch: 284 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 285/300 ---\n",
      "Epoch: 285 | Average Training Loss: 0.000002\n",
      "Epoch: 285 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 285 | Average Val Loss: 0.000071\n",
      "Epoch: 285 | Average Euclidean Distance: 0.0140\n",
      "\n",
      "--- Epoch 286/300 ---\n",
      "Epoch: 286 | Average Training Loss: 0.000002\n",
      "Epoch: 286 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 286 | Average Val Loss: 0.000073\n",
      "Epoch: 286 | Average Euclidean Distance: 0.0140\n",
      "\n",
      "--- Epoch 287/300 ---\n",
      "Epoch: 287 | Average Training Loss: 0.000002\n",
      "Epoch: 287 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 287 | Average Val Loss: 0.000069\n",
      "Epoch: 287 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 288/300 ---\n",
      "Epoch: 288 | Average Training Loss: 0.000002\n",
      "Epoch: 288 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 288 | Average Val Loss: 0.000068\n",
      "Epoch: 288 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 289/300 ---\n",
      "Epoch: 289 | Average Training Loss: 0.000002\n",
      "Epoch: 289 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 289 | Average Val Loss: 0.000068\n",
      "Epoch: 289 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 290/300 ---\n",
      "Epoch: 290 | Average Training Loss: 0.000002\n",
      "Epoch: 290 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 290 | Average Val Loss: 0.000068\n",
      "Epoch: 290 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 291/300 ---\n",
      "Epoch: 291 | Average Training Loss: 0.000002\n",
      "Epoch: 291 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 291 | Average Val Loss: 0.000074\n",
      "Epoch: 291 | Average Euclidean Distance: 0.0140\n",
      "\n",
      "--- Epoch 292/300 ---\n",
      "Epoch: 292 | Average Training Loss: 0.000002\n",
      "Epoch: 292 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 292 | Average Val Loss: 0.000073\n",
      "Epoch: 292 | Average Euclidean Distance: 0.0140\n",
      "\n",
      "--- Epoch 293/300 ---\n",
      "Epoch: 293 | Average Training Loss: 0.000002\n",
      "Epoch: 293 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 293 | Average Val Loss: 0.000069\n",
      "Epoch: 293 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 294/300 ---\n",
      "Epoch: 294 | Average Training Loss: 0.000002\n",
      "Epoch: 294 | Average Euclidean Distance: 0.0027\n",
      "Epoch: 294 | Average Val Loss: 0.000066\n",
      "Epoch: 294 | Average Euclidean Distance: 0.0137\n",
      "⭐ New Best Model Saved! (Best MRE: 0.013726)\n",
      "\n",
      "--- Epoch 295/300 ---\n",
      "Epoch: 295 | Average Training Loss: 0.000002\n",
      "Epoch: 295 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 295 | Average Val Loss: 0.000067\n",
      "Epoch: 295 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 296/300 ---\n",
      "Epoch: 296 | Average Training Loss: 0.000002\n",
      "Epoch: 296 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 296 | Average Val Loss: 0.000070\n",
      "Epoch: 296 | Average Euclidean Distance: 0.0139\n",
      "\n",
      "--- Epoch 297/300 ---\n",
      "Epoch: 297 | Average Training Loss: 0.000002\n",
      "Epoch: 297 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 297 | Average Val Loss: 0.000068\n",
      "Epoch: 297 | Average Euclidean Distance: 0.0138\n",
      "\n",
      "--- Epoch 298/300 ---\n",
      "Epoch: 298 | Average Training Loss: 0.000002\n",
      "Epoch: 298 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 298 | Average Val Loss: 0.000071\n",
      "Epoch: 298 | Average Euclidean Distance: 0.0140\n",
      "\n",
      "--- Epoch 299/300 ---\n",
      "Epoch: 299 | Average Training Loss: 0.000002\n",
      "Epoch: 299 | Average Euclidean Distance: 0.0027\n",
      "Epoch: 299 | Average Val Loss: 0.000066\n",
      "Epoch: 299 | Average Euclidean Distance: 0.0137\n",
      "⭐ New Best Model Saved! (Best MRE: 0.013719)\n",
      "\n",
      "--- Epoch 300/300 ---\n",
      "Epoch: 300 | Average Training Loss: 0.000002\n",
      "Epoch: 300 | Average Euclidean Distance: 0.0026\n",
      "Epoch: 300 | Average Val Loss: 0.000072\n",
      "Epoch: 300 | Average Euclidean Distance: 0.0140\n",
      "\n",
      "==============================\n",
      "TRAINING COMPLETE. RUNNING FINAL TEST...\n",
      "Epoch: FINAL | Average Val Loss: 0.000069\n",
      "Epoch: FINAL | Average Euclidean Distance: 0.0141\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T10:26:55.853620500Z",
     "start_time": "2026-02-02T10:26:46.457884800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Device: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"Compute Capability: {torch.cuda.get_device_capability(0)}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"PyTorch CUDA: {torch.version.cuda}\")\n",
    "\n",
    "path = \"Aariz Dataset\"#\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model  = CephNet()\n",
    "\n",
    "model.to(device)\n",
    "batch_size = 5\n",
    "\n",
    "model.load_state_dict(torch.load(\"best_model_epoch_195.pth\"))\n",
    "\n",
    "test_data = AarizDataset( path ,\"TEST\")\n",
    "test_dataloader = DataLoader(training_data, batch_size=batch_size,shuffle=True)\n",
    "\n",
    "for (images,_) in test_dataloader:\n",
    "    images = images.to(device)\n",
    "    output =model(images)\n",
    "    draw_batch(images, output)\n",
    "    print(f\"Shape of Output batch: {output.shape}\")\n",
    "    break\n"
   ],
   "id": "251476befaeaab70",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: NVIDIA GeForce RTX 5080 Laptop GPU\n",
      "Compute Capability: (12, 0)\n",
      "PyTorch Version: 2.10.0+cu128\n",
      "PyTorch CUDA: 12.8\n",
      "Shape of Output batch: torch.Size([5, 29, 2])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "\n",
   "id": "78207fdebd3d719f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
